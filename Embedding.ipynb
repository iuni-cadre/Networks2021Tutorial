{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial CADRE 2021\n",
    "\n",
    "In this tutorial we will illustrate a modern Machine Learning pipeline applied to scholarly data. This should cover:\n",
    "\n",
    " * Loading query results data\n",
    " * Building a citation network\n",
    " * Obtaining an embedding of the network by employing Node2Vec\n",
    "   * Generating random walks sentences\n",
    "   * Train a Word2Vec model from it\n",
    " * Generate 2D positions from the embedding by using UMAP\n",
    " * Interactive visualization of the embedding\n",
    " * SemAxis exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import xnetwork as xnet\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import sys\n",
    "import os\n",
    "import cxrandomwalk as rw\n",
    "import umap\n",
    "import gensim\n",
    "import importlib\n",
    "import matplotlib\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from collections import OrderedDict\n",
    "import matplotlib.patheffects as pe\n",
    "import scipy.stats as scistats\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the query ID here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryID = \"ScientometricsInformetrics_f3a00751-ef8e-42ed-b785-8419098c0a67\"\n",
    "\n",
    "interactive = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up some folders and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"networks\",exist_ok=True)\n",
    "networkPath = \"networks/\"+queryID+\".xnet\"\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "modelPath = \"models/%s.model\"%queryID\n",
    "\n",
    "os.makedirs(\"sentences\", exist_ok=True)\n",
    "sentencesPath = \"sentences/%s.txt\"%queryID\n",
    "\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "networkPath = \"networks/\"+queryID+\".xnet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fields available for MAG queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGColumnTypes = {\n",
    "    \"Paper_paperId\":int,\n",
    "    'Affiliation_displayName': str,\n",
    "    'Author_authorId': str,\n",
    "    'Author_rank': str,\n",
    "    'Author_displayName': str,\n",
    "    'Author_lastKnownAffiliationId': str,\n",
    "    'Paper_bookTitle': str,\n",
    "    'ConferenceInstance_conferenceInstanceId': str,\n",
    "    'Paper_date': str,\n",
    "    'Paper_docType': str,\n",
    "    'Paper_doi': str,\n",
    "    'FieldOfStudy_fieldOfStudyId': str,\n",
    "    'Paper_issue': str,\n",
    "    'JournalFixed_displayName': str,\n",
    "    'JournalFixed_journalIdFixed': str,\n",
    "    'JournalFixed_issn': str,\n",
    "    'JournalFixed_publisher': str,\n",
    "    'Paper_originalTitle': str,\n",
    "    'Paper_citationCount': int,\n",
    "    'Paper_estimatedCitation': int,\n",
    "    'Paper_firstPage': str,\n",
    "    'Paper_lastPage': str,\n",
    "    'Paper_publisher': str,\n",
    "    'Paper_referenceCount': int,\n",
    "    'Paper_paperTitle': str,\n",
    "    'Paper_year': int,\n",
    "    'isQueryPaper': str,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to build a citation network from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_query_input_to_xnet(nodes_file, edges_file, output_file):\n",
    "    global edgesData,nodesData,vertexAttributes,index2ID,graph\n",
    "    edgesData = pd.read_csv(edges_file)\n",
    "    nodesData = pd.read_csv(nodes_file, dtype=MAGColumnTypes)\n",
    "\n",
    "    # Replacing NaN for empty string\n",
    "    for key in MAGColumnTypes:\n",
    "        if(key in nodesData):\n",
    "            nodesData[key].fillna(\"\",inplace=True)\n",
    "\n",
    "    # Generating continous indices for papers\n",
    "    index2ID  = nodesData[\"Paper_paperId\"].tolist()\n",
    "    ID2Index = {id:index for index, id in enumerate(index2ID)}\n",
    "\n",
    "\n",
    "    # Hack to account for 2 degree capitalized \"FROM\"\n",
    "    fromKey = \"From (Citing)\"\n",
    "\n",
    "    toKey = \"To (Cited)\"\n",
    "    \n",
    "    # Converting edges from IDs to new indices\n",
    "    # Invert edges so it means a citation between from to to\n",
    "    edgesZip = zip(edgesData[fromKey].tolist(),edgesData[toKey].tolist())\n",
    "    edgesList = [(ID2Index[toID],ID2Index[fromID]) for fromID,toID in edgesZip if fromID in ID2Index and toID in ID2Index]\n",
    "\n",
    "    vertexAttributes = {key:nodesData[key].tolist() for key in nodesData if key in MAGColumnTypes}\n",
    "    \n",
    "    for key,data in vertexAttributes.items():\n",
    "        if (isinstance(data[0],str)):\n",
    "            vertexAttributes[key] = [sEntry if len(sEntry)>0 else \"None\" for sEntry in [entry.strip(\"[]\") for entry in data]]\n",
    "            \n",
    "    graph = ig.Graph(\n",
    "        n=len(index2ID),\n",
    "        edges=edgesList,\n",
    "        directed=True,\n",
    "        vertex_attrs=vertexAttributes\n",
    "    )\n",
    "\n",
    "    verticesToDelete = np.where(np.array([value==\"false\" for value in graph.vs[\"isQueryPaper\"]]))[0]\n",
    "    graph.delete_vertices(verticesToDelete)\n",
    "    graph.vs[\"KCore\"] = graph.shell_index(mode=\"IN\")\n",
    "    graph.vs[\"In-Degree\"] = graph.degree(mode=\"IN\")\n",
    "    graph.vs[\"Out-Degree\"] = graph.degree(mode=\"OUT\")\n",
    "\n",
    "    if(\"Paper_year\" in graph.vertex_attributes()):\n",
    "        graph.vs[\"year\"] = [int(year) for year in graph.vs[\"Paper_year\"]]\n",
    "    else:\n",
    "        graph.vs[\"year\"] = [int(s[0:4]) for s in graph.vs[\"date\"]]\n",
    "    \n",
    "    giantComponent = graph.clusters(mode=\"WEAK\").giant()\n",
    "    giantCopy = giantComponent.copy()\n",
    "    giantCopy.to_undirected()\n",
    "    giantComponent.vs[\"Community\"] = [str(c) for c in giantCopy.community_multilevel().membership]\n",
    "    xnet.igraph2xnet(giantComponent, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating and saving the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_query_input_to_xnet(\n",
    "        \"../query-results/%s.csv\"%queryID,\n",
    "        \"../query-results/%s_edges.csv\"%queryID,\n",
    "        networkPath\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and testing the generated network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = xnet.xnet2igraph(networkPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "class MonitorCallback(CallbackAny2Vec):\n",
    "    def __init__(self,pbar):\n",
    "        self.pbar = pbar\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.refresh() # to show immediately the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating random walks in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970c56e4d18e45129ebcdd0c8edf4eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = rw.Agent(g.vcount(),np.array(g.get_edgelist()),False);\n",
    "\n",
    "def make_pbar():\n",
    "    pbar = None\n",
    "    def inner(current,total):\n",
    "        nonlocal pbar\n",
    "        if(pbar is None):\n",
    "            pbar= tqdm(total=total);\n",
    "        pbar.update(current - pbar.n)\n",
    "    return inner\n",
    "\n",
    "agent.generateWalks(q=1.0,p=1.0,filename=sentencesPath,walksPerNode=10,verbose=False,updateInterval=100,callback=make_pbar()) #filename=\"entireData.txt\",\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a982c86b3ec74da0893bd11ef15084f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "monitor = MonitorCallback(tqdm())\n",
    "gensimModel = gensim.models.Word2Vec(\n",
    "    gensim.models.word2vec.LineSentence(sentencesPath),\n",
    "    vector_size=64,\n",
    "    workers=2,\n",
    "    min_count=1,\n",
    "    sg=1,\n",
    "    callbacks=[monitor]\n",
    ")#,negative=10)\n",
    "\n",
    "gensimModel.save(modelPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the UMAP projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(angular_rp_forest=True, dens_frac=0.0, dens_lambda=0.0, metric='cosine',\n",
      "     min_dist=0.25, n_neighbors=14, verbose=True)\n",
      "Construct fuzzy simplicial set\n",
      "Mon Jun 21 14:35:58 2021 Finding Nearest Neighbors\n",
      "Mon Jun 21 14:35:58 2021 Building RP forest with 9 trees\n",
      "Mon Jun 21 14:36:01 2021 NN descent for 13 iterations\n",
      "\t 1  /  13\n",
      "\t 2  /  13\n",
      "\t 3  /  13\n",
      "\t 4  /  13\n",
      "\t 5  /  13\n",
      "\tStopping threshold met -- exiting after 5 iterations\n",
      "Mon Jun 21 14:36:57 2021 Finished Nearest Neighbor Search\n",
      "Mon Jun 21 14:37:07 2021 Construct embedding\n",
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n",
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Mon Jun 21 14:37:50 2021 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "gensimModel = gensim.models.Word2Vec.load(modelPath)\n",
    "gensimVector = gensimModel.wv;\n",
    "reducer = umap.UMAP(n_neighbors=14, min_dist=0.25, n_components=2, metric='cosine',verbose=True)\n",
    "embedding = reducer.fit_transform(gensimVector.vectors)\n",
    "\n",
    "keyindex = {int(entry):i for i,entry in enumerate(gensimVector.index_to_key)}\n",
    "indexkey = [keyindex[index] for index in sorted(keyindex.keys())]\n",
    "correctOriginalEmbedding = gensimVector.vectors[indexkey,:]\n",
    "correctEmbedding = embedding[indexkey,:]\n",
    "\n",
    "g.vs['Position'] = correctEmbedding\n",
    "xnet.igraph2xnet(g,networkPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lightness(color, amount=0.5):\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], amount, c[2])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive visualization\n",
    "#### Visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateVisualization(nameAttribute,sizeAttribute,colorAttribute,nNeighbors,legendColumns = 2, exportFilename = None):\n",
    "    x = correctEmbedding[:, 0]\n",
    "    y = correctEmbedding[:, 1]\n",
    "\n",
    "    names = g.vs[nameAttribute]#np.array([str(i) for i in range(len(x))])\n",
    "    colorValues = g.vs[colorAttribute]\n",
    "    from collections import Counter\n",
    "    valuesCounter = Counter(colorValues)\n",
    "    if(\"None\" in valuesCounter):\n",
    "        valuesCounter[\"None\"] = 1\n",
    "    sortedTitles = [pair[0] for pair in sorted(valuesCounter.items(), key=lambda item: item[1],reverse=True)]\n",
    "    c2i = {c:i if i<10 else 10 for i,c in enumerate(sortedTitles)}\n",
    "    c2cc = {c:cm.tab10(i)[0:3]+(0.25,) if i<10 else (0.75,0.75,0.75,0.05) for i,c in enumerate(sortedTitles)} \n",
    "    c2ccLight = {c:adjust_lightness(cm.tab10(i)[0:3]+(0.25,),0.98) if i<10 else adjust_lightness((0.75,0.75,0.75,1.00),0.98) for i,c in enumerate(sortedTitles)}\n",
    "    colors = [c2cc[entry] for entry in colorValues];\n",
    "    colorsLight = [c2ccLight[entry] for entry in colorValues];\n",
    "    c = colors\n",
    "    if(sizeAttribute in g.vertex_attributes()):\n",
    "        sizes = 1+4*np.log(1.0+np.array(g.vs[sizeAttribute]))\n",
    "    else:\n",
    "        sizes = 5\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(6,8))\n",
    "    sc = plt.scatter(x,y,c=c, s=sizes, pickradius=1)\n",
    "\n",
    "    annot = ax.annotate(\"\", xy=(0,0), xytext=(5,5),textcoords=\"figure pixels\",\n",
    "                        bbox=dict(boxstyle=\"round\", fc=\"w\",ec=\"w\"),\n",
    "                        arrowprops=dict(arrowstyle=\"fancy\",lw=0.5))\n",
    "    annot.set_visible(False)\n",
    "    xlim = ax.get_xlim()\n",
    "    linesBack = []\n",
    "    for _ in range(nNeighbors):\n",
    "        line = ax.plot([0,0],[0,0],lw=4,c=\"k\",\n",
    "                       solid_capstyle='round',\n",
    "                       picker=False)[0]\n",
    "        line.set_visible(False)\n",
    "        linesBack.append(line)\n",
    "\n",
    "    lines = []\n",
    "    for _ in range(nNeighbors):\n",
    "        line = ax.plot([0,0],[0,0],lw=2,c=\"r\",\n",
    "                       solid_capstyle='round',\n",
    "                       picker=False)[0]\n",
    "        line.set_visible(False)\n",
    "        lines.append(line)\n",
    "\n",
    "    def update_annot(ind):\n",
    "        selectedIndex = ind[\"ind\"][0]\n",
    "        annot.xy = sc.get_offsets()[selectedIndex]\n",
    "        for line in lines:\n",
    "            line.set_visible(False)\n",
    "        for line in linesBack:\n",
    "            line.set_visible(False)\n",
    "        neighborsData = [(int(i),float(p)) for i,p in gensimModel.wv.most_similar(str(selectedIndex), topn=nNeighbors)]\n",
    "        for i,(index,p) in enumerate(neighborsData):\n",
    "            pos = (x[index],y[index])\n",
    "            line = lines[i]\n",
    "            lineBack = linesBack[i]\n",
    "            lineData = line.get_data()\n",
    "            line.set_xdata([x[selectedIndex],x[index]])\n",
    "            line.set_ydata([y[selectedIndex],y[index]])\n",
    "            lineBack.set_xdata([x[selectedIndex],x[index]])\n",
    "            lineBack.set_ydata([y[selectedIndex],y[index]])\n",
    "            line.set_visible(True)\n",
    "            lineBack.set_visible(True)\n",
    "            line.set_alpha(p)\n",
    "            lineBack.set_alpha(p)\n",
    "    #     annot.set_position((-0,-0)) + str(number) + \"}$\"\n",
    "        text = \"{}\".format(\"\\n\".join([names[selectedIndex]]+[names[n] for n in [v for v,p in neighborsData]]))\n",
    "        text = text.replace(\"$\",'\\$')\n",
    "        annot.set_text(text)\n",
    "        annot.arrow_patch.set_facecolor(c[ind[\"ind\"][0]])\n",
    "        annot.arrow_patch.set_edgecolor(\"w\")\n",
    "        annot.get_bbox_patch().set_facecolor(colorsLight[ind[\"ind\"][0]])\n",
    "        annot.get_bbox_patch().set_alpha(1.0)\n",
    "\n",
    "\n",
    "    def hover(event):\n",
    "        vis = annot.get_visible()\n",
    "        if event.inaxes == ax:\n",
    "            cont, ind = sc.contains(event)\n",
    "            if cont:\n",
    "                update_annot(ind)\n",
    "                annot.set_visible(True)\n",
    "                fig.canvas.draw_idle()\n",
    "            else:\n",
    "                if vis:\n",
    "                    annot.set_visible(False)\n",
    "                    for line in lines:\n",
    "                        line.set_visible(False)\n",
    "                    for line in linesBack:\n",
    "                        line.set_visible(False)\n",
    "                    fig.canvas.draw_idle()\n",
    "    \n",
    "    if(exportFilename is None):\n",
    "        fig.canvas.mpl_connect(\"button_press_event\", hover)\n",
    "    \n",
    "    plt.setp(ax, xticks=[], yticks=[]);\n",
    "    fig.patch.set_visible(False)\n",
    "    ax.axis('off')\n",
    "    legend_elements = [Line2D([0], [0],\n",
    "                        linewidth=0,\n",
    "                        marker='o',\n",
    "                        color=c2cc[community][0:3],\n",
    "                        label=community,\n",
    "                        # markerfacecolor='g',\n",
    "                        markersize=3) for community in sortedTitles[0:10]]\n",
    "    legend_elements+=[Line2D([0], [0],\n",
    "                        linewidth=0,\n",
    "                        marker='o',\n",
    "                        color=(0.75,0.75,0.75),\n",
    "                        label=\"Others\",\n",
    "                        # markerfacecolor='g',\n",
    "                        markersize=3)]\n",
    "    ax.legend(handles=legend_elements,\n",
    "              fontsize=\"small\",\n",
    "              frameon=False,\n",
    "              fancybox=False,\n",
    "              ncol=legendColumns,\n",
    "              bbox_to_anchor=(0.0, 1.1),\n",
    "              loc='upper left')\n",
    "\n",
    "    \n",
    "    fig.subplots_adjust(bottom=0.25,top=0.90,left=0.0,right=1.0)\n",
    "    if(exportFilename is None):\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(exportFilename)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Parameters\n",
    "Choose the names of the attributes to be used for  visualization and number of neigbohrs to show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce8dd9d7aa9431a88af89e6c9f94457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(interactive):\n",
    "    exportFilename = None\n",
    "else:\n",
    "    exportFilename = \"figures/embedding.pdf\"\n",
    "\n",
    "generateVisualization(\n",
    "    nameAttribute = \"Paper_originalTitle\",\n",
    "    sizeAttribute = \"Paper_citationCount\",\n",
    "#     colorAttribute = \"JournalFixed_displayName\",\n",
    "    colorAttribute = \"Community\",\n",
    "    nNeighbors = 10,\n",
    "    legendColumns = 4,\n",
    "    exportFilename=exportFilename\n",
    ")\n",
    "####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemAxis approach\n",
    "In this example we use a few samples of extremes for two groups (for instance past for papers published before 2000 and recent for papers published after 2015). Other classes can be used as well, for instnace journals or citations.\n",
    "Importing code directly from the emlens package (https://github.com/skojaku/emlens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semaxis support from the emlens package (https://github.com/skojaku/emlens)\n",
    "# https://github.com/skojaku/emlens/blob/main/emlens/semaxis.py\n",
    "import emlens_semaxis as emlens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paramaters for SemAxis\n",
    "Here we define the rules to assign nodes to each group. `maxSamples` indicate the number of samples per classes that are going to be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nameAttribute' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a4d1eb187bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnameAttribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgroupMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nameAttribute' is not defined"
     ]
    }
   ],
   "source": [
    "maxSamples = 20; # max samples per class\n",
    "\n",
    "nameAttribute = \"Paper_originalTitle\"\n",
    "groupAttribute =\"year\"\n",
    "\n",
    "groups = {\n",
    "    \"Recent\": lambda v : v>2015,\n",
    "    \"Past\": lambda v : v<2000,\n",
    "}\n",
    "\n",
    "# \n",
    "# groupAttribute =\"JournalFixed_displayName\"\n",
    "\n",
    "\n",
    "# groups = {\n",
    "#     \"Nature Cell Biology\": lambda v : v == \"Nature Cell Biology\",\n",
    "#     \"Nature Physics\": lambda v : v == \"Nature Physics\",\n",
    "# }\n",
    "\n",
    "labels = np.array(g.vs[nameAttribute])\n",
    "\n",
    "def groupMap(index):\n",
    "    groupValue = g.vs[groupAttribute][index]\n",
    "    for groupName,func  in groups.items():\n",
    "        if(func(groupValue)):\n",
    "            return groupName;\n",
    "    else:\n",
    "        return None # no group\n",
    "\n",
    "    \n",
    "groupIDs = np.array(list(map(groupMap,range(g.vcount()))))\n",
    "validGroups = np.array([entry is not None for entry in groupIDs])\n",
    "\n",
    "if(maxSamples>=0):\n",
    "    for groupName in groups:\n",
    "        groupIndices = np.where(groupIDs==groupName)[0]\n",
    "        if(len(groupIndices)>maxSamples):\n",
    "            validGroups[groupIndices] = False;\n",
    "            validGroups[np.random.choice(groupIndices,maxSamples,replace=False)] = True\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "model = emlens.SemAxis()\n",
    "model.fit(correctOriginalEmbedding[validGroups,:], groupIDs[validGroups])\n",
    "projectedCoordinates = model.transform(correctOriginalEmbedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of the semAxis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(13,5))\n",
    "otherGroup = np.ones(len(groupIDs),dtype=bool)\n",
    "bins = 30\n",
    "\n",
    "for groupName in groups:\n",
    "    otherGroup*=(groupIDs!=groupName)\n",
    "    groupCoordinates = projectedCoordinates[groupIDs==groupName]\n",
    "    if(len(groupCoordinates)):\n",
    "        p = plt.hist(groupCoordinates,bins=bins,density=True,label=groupName,alpha=0.70)\n",
    "    \n",
    "groupCoordinates = projectedCoordinates[otherGroup]\n",
    "if(len(groupCoordinates)):\n",
    "    p = plt.hist(groupCoordinates,bins=bins,density=True,label=\"Other\",alpha=0.70)\n",
    "    \n",
    "\n",
    "# average\n",
    "\n",
    "fig.subplots_adjust(bottom=0.10,top=0.20,left=0.0,right=0.45)\n",
    "ax.legend(fontsize=\"small\",\n",
    "          frameon=False,\n",
    "          fancybox=False,\n",
    "          bbox_to_anchor=(0.0, 8),\n",
    "          loc='upper left')\n",
    "\n",
    "plt.setp(ax, yticks=[]);\n",
    "fig.patch.set_visible(False)\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.set_xlabel(\"SemAxis\")\n",
    "\n",
    "breaks = 15\n",
    "step = (np.max(projectedCoordinates)-np.min(projectedCoordinates))/breaks;\n",
    "addedIndices = []\n",
    "sortedIndices = sorted(range(len(projectedCoordinates)),key=lambda i: projectedCoordinates[i])\n",
    "for i in sortedIndices:\n",
    "    if(projectedCoordinates[i] >= np.min(projectedCoordinates)+len(addedIndices)*step):\n",
    "        addedIndices.append(i)\n",
    "        \n",
    "for index in addedIndices:\n",
    "#     index = 6069\n",
    "    groupName = groupIDs[index]\n",
    "    plt.scatter([projectedCoordinates[index]],[1.0],s=10, c = \"k\",\n",
    "                clip_on=False,\n",
    "                transform = ax.get_xaxis_transform())\n",
    "    textActor = ax.text(projectedCoordinates[index], 1.1, labels[index], fontsize=8,\n",
    "                  rotation=45, rotation_mode='anchor',\n",
    "    #               transform_rotates_text=True,\n",
    "                   transform = ax.get_xaxis_transform())\n",
    "    textActor.set_path_effects([pe.Stroke(linewidth=2, foreground='white'),\n",
    "                       pe.Normal()])\n",
    "\n",
    "ax.scatter(0.2, projectedCoordinates[index])\n",
    "\n",
    "if(interactive):\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(\"figures/semaxis.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example analysis\n",
    "Here we check if the semiaxis correlate with publication year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = g.vs[\"year\"]\n",
    "y = projectedCoordinates\n",
    "plt.title(\"Pearson Corr.: %.2f, Spearman Corr.: %.2f\"%(scistats.pearsonr(x, y)[0],scistats.spearmanr(x, y)[0]))\n",
    "plt.hexbin(x,y,gridsize=25,cmap=cm.inferno)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"SemAxis\")\n",
    "plt.show()\n",
    "if(interactive):\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig(\"figures/yearCorrelation.pdf\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
